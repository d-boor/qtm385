{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"QTM 385 - Experimental Methods\"\n",
        "subtitle: Assignment 03\n",
        "---\n",
        "\n",
        "# Instructions\n",
        "\n",
        "This assignment covers the last two lectures of the course. As usual, it consists of 10 questions, each worth one point. You can answer the questions in any format you prefer, but I recommend using Jupyter Notebooks and converting the answers to PDF or html, as they are easier to read on Canvas. Please write at least one or two paragraphs for each written question.\n",
        "\n",
        "If you have any questions about the assignment, feel free to email me at <danilo.freire@emory.edu>.\n",
        "\n",
        "Good luck!\n",
        "\n",
        "# Questions \n",
        "\n",
        "1. Compare and contrast Type I and Type II errors. In causal inference experiments, why might a researcher be more concerned with one type of error over the other?\n",
        "\n",
        "2. Explain the concept of randomisation inference and outline its advantages over traditional parametric tests, especially in the context of testing the sharp null hypothesis.\n",
        "\n",
        "3. Compare Neyman’s hypothesis testing framework with Fisher’s sharp null hypothesis approach. What are the main advantages and disadvantages of each method in experimental settings?\n",
        "\n",
        "4. Critically evaluate the use of p-values in hypothesis testing. What alternatives are suggested (or implied) in the lectures, and what are the potential benefits of these alternatives?\n",
        "\n",
        "5. The code below simulates a dataset. Modify the code so that it adds a new variable called `treat` with 500 treated individuals and 500 control individuals (complete random assignment). Also include a binary covariate called `gender` (0 = male, 1 = female; with equal probability) and update the outcome (`interviews`) by adding 2 points if the individual is female.\n",
        "\n",
        "```r\n",
        "## Set seed for reproducibility\n",
        "set.seed(385)\n",
        "\n",
        "# Load packages\n",
        "# install.packages(\"fabricatr\")\n",
        "# install.packages(\"randomizr\") # if you haven't installed them yet\n",
        "library(fabricatr)\n",
        "library(randomizr)\n",
        "\n",
        "## Simulate data\n",
        "data <- fabricate(\n",
        "  N = 1000,\n",
        "  treat= complete_ra(N, m=500)\n",
        "  gender= complete_ra(N, p=0.50)\n",
        "\n",
        "  interviews = round(rnorm(1000, mean = 10, sd = 2) + 5 * treat + 2* gender, digits = 0)\n",
        ")\n",
        "head(data)\n",
        "```\n",
        "\n",
        "6. Using the dataset created in the previous question, estimate the average treatment effect on the outcome `interviews` using the `lm_robust()` function from the `estimatr` package. Interpret the results.\n",
        "\n",
        "7. Using the same dataset, estimate the average treatment effect of the treatment on the outcome `interviews` using randomisation inference. Interpret the results.\n",
        "\n",
        "8. Explain how including covariates in an experimental regression model can increase the precision of the treatment effect estimate. Under what conditions might this adjustment lead to biased estimates?\n",
        "\n",
        "9. Simulate a dataset with heterogeneous treatment effects (e.g., the treatment effect is larger for individuals with higher education). Estimate the treatment effect for different subgroups using an interaction term.\n",
        "\n",
        "10. Why is the publication of null results important in experimental research? What are the main challenges in publishing null results, and how can the scientific community address these challenges?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1: Type one errors can be considered a false positive, where one rejects the null when they should not have. Type two errors are false negative, not rejecting the null when you should have. Type one errors are considered more severe as researchers can be using wrong assumptions due to the error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2: Randomization Inference is helpful as we do not need to assume n going to infinity and treatment become the only real \"random\" portion of the data. Using the Fisher test we can can use the sharp null hypothesis, that for each individual the treatment effect is zero, and because of this the observed outcome is equal to the unseen outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3: Neymans hypothesis test surrounds the idea that ON AVERAGE the treatment effect is zero, and we must disprove this. This means that for each individual there might be some difference between treated and untreated, but we cannot be sure so instead we look at averages. When we compare this to Fisher we assume that for each individual the treatment effect is zero and we must disprove this. This means that there are no unknown treatments, as if a treated individual gets 54 untis then we say that their untreated self would have gotten at 54 as well. FIsher is helpful for finding if there is any treatment effect and when the sample size is small, as  Neyman can help estmates the actual treatment effect and is better when n is larger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "type object 'set' has no attribute 'seed'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mset\u001b[39m\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m385\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load packages\u001b[39;00m\n\u001b[0;32m      4\u001b[0m install\u001b[38;5;241m.\u001b[39mpackages(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfabricatr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: type object 'set' has no attribute 'seed'"
          ]
        }
      ],
      "source": [
        "set.seed(385)\n",
        "\n",
        "# Load packages\n",
        "install.packages(\"fabricatr\")\n",
        "install.packages(\"randomizr\") # if you haven't installed them yet\n",
        "library(fabricatr)\n",
        "library(randomizr)\n",
        "\n",
        "## Simulate data\n",
        "data <- fabricate(\n",
        "  N = 1000,\n",
        "  treat=complete_ra(N, m=500),\n",
        "  gender=complete_ra(N, p=0.50),\n",
        "  interviews = round(rnorm(1000, mean = 10, sd = 2) + 5 * treat + 2* gender, digits = 0)\n",
        ")\n",
        "head(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "pip show radian\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
